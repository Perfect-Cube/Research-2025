{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9e8eaec-b1ce-4d64-926e-012af3b37b42",
   "metadata": {},
   "source": [
    "# Run a script to interact with chatGPT \n",
    "\n",
    "Now that we have a python environment equipped to communicate with OpenAI, let’s interact with ChatGPT from it! \n",
    "Let's first import the `openai` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37177dc0-00f1-4ea4-be8e-417a963ad0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ad39e-1151-460d-87d9-9ed41f50e792",
   "metadata": {},
   "source": [
    "We are now going to create a `client` object that will be used to connect with OpenAI. We're going to use our OpenAI API key to point toward our OpenAI account and use our credit, the connection will otherwise be refused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bb8b15-e88b-4566-a61b-764485be9167",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msk-proj-GjIUEqAKI2j04dlC18rZT3BlbkFJnLTC5AeosFLwmSAxKzNU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_client.py:107\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_stream_cls \u001b[38;5;241m=\u001b[39m Stream\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletions \u001b[38;5;241m=\u001b[39m resources\u001b[38;5;241m.\u001b[39mCompletions(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:746\u001b[0m, in \u001b[0;36mSyncAPIClient.__init__\u001b[1;34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[0m\n\u001b[0;32m    731\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m DEFAULT_TIMEOUT\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    734\u001b[0m     version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[0;32m    735\u001b[0m     limits\u001b[38;5;241m=\u001b[39mlimits,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    744\u001b[0m     _strict_response_validation\u001b[38;5;241m=\u001b[39m_strict_response_validation,\n\u001b[0;32m    745\u001b[0m )\n\u001b[1;32m--> 746\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m http_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mhttpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;49;00m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_custom_http_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(http_client)\n",
      "\u001b[1;31mTypeError\u001b[0m: Client.__init__() got an unexpected keyword argument 'proxies'"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=\"sk-proj-GjIUEqAKI2j04dlC18rZT3BlbkFJnLTC5AeosFLwmSAxKzNU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b73e5d-50ff-4cdb-a017-e2b8a48eac53",
   "metadata": {},
   "source": [
    "If your API key is valid, you should not get any error messages. \n",
    "\n",
    "Next, we are going to use a basic command from the OpenAI command to basically chat with chatGPT3.5-turbo. We'll use chatGPT4 in this class, but the cost of 3.5 is much cheaper, so whenever we don't really need the performance of 4, we'll rely on 3.5. \n",
    "\n",
    "## The system prompt\n",
    "\n",
    "An important difference with how you use chatGPT on your browser is that we'll specify a `system prompt` message.\n",
    "\n",
    "The `system prompt` basically asks chatGPT to adopt a certain role for the following conversation. \n",
    "We specify the system prompt with: `\"role\": \"system\"`. \n",
    "\n",
    "We then send a request using `\"role\": \"user\"`.\n",
    "\n",
    "## Sending our first request\n",
    "\n",
    "Let's ask chatGPT3.5 to answer a message while playing a specifc role, we'll use a standard example here.\n",
    "\n",
    "The **system prompt** is: \"*You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.*\";  \n",
    "And the **message** is: \"*Compose a poem that explains the concept of recursion in programming.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06dcb55b-2b51-40ac-b552-cb8410ac3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171dab51-5155-4ce8-82e1-b92d49289ef2",
   "metadata": {},
   "source": [
    "If we don't get any error message, this means that the request went well and that we can now display its result. The result will be stored in the `choices` field of the `completion` object. We can display it using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e84e6b4-029c-41f0-b991-55a0f7f7f4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='In the realm of code where logic thrives,  \\nA dance of functions, where magic derives,  \\nThere lies a tale of a loop so fine,  \\nA wondrous spiral, both sleek and divine.  \\n\\nRecursion, dear friend, is a mystical call,  \\nWhere functions embrace, and one leads to all.  \\n“Call me again!” they whisper in glee,  \\nAs they dive through the layers, setting minds free.  \\n\\nA function invokes, with a spark of delight,  \\nIt breaks down the problem, shedding its light.  \\n“Base case!” it cries, “The end is in sight!  \\nWhen the simple is reached, all shall be right.”  \\n\\nBut wait! There’s more to this story so grand,  \\nAs the function unwinds, like grains of fine sand.  \\nEach step a reminder of paths we have tread,  \\nReconstructing the answers, with wisdom well-fed.  \\n\\nFibonacci’s numbers, in nature they twine,  \\nA recursive descent, a growth so divine.  \\nFrom zero to one, two follows the dance,  \\nEach call builds upon with a magical chance.  \\n\\nBut beware the deep woods, where infinite lies,  \\nFor without a good base, your function may rise,  \\nInto endless recursion, a stack frame’s regret,  \\nA crash on the shores of a logic upset.  \\n\\nSo harness this power, let it guide your way,  \\nTo solve complex puzzles, both night and day.  \\nWith a flick of the mind, and a recursive embrace,  \\nYou’ll craft wondrous programs, a coder’s true grace.  \\n\\nIn this dance of the intellect, elegant and neat,  \\nRecursion, my friend, is a rhythm so sweet.  \\nA cycle of calls, a beautiful feat,  \\nIn the heart of our code, where all functions meet.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42586d5c-ecb6-4a33-bad0-136f124f87eb",
   "metadata": {},
   "source": [
    "So we were just able to interact with OpenAI's chatGPT from python! This is the first step necessary to build AI apps that rely on agents!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
