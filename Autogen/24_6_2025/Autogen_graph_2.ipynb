{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNLxGKhO_mfm",
        "outputId": "a36ae05c-b46d-4a21-ee4d-4aea7637d7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Installing system packages for Graphviz...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "‚úÖ System packages installed.\n",
            "‚è≥ Installing Python libraries (autogen, gradio, groq, etc.)...\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement gliclass>=0.2.1 (from versions: 0.1.0, 0.1.1, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.1.10, 0.1.11)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for gliclass>=0.2.1\u001b[0m\u001b[31m\n",
            "\u001b[0m‚úÖ Python libraries installed.\n",
            "‚úÖ Groq API Key set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install Dependencies and Setup Environment\n",
        "\n",
        "# 1. Install system-level packages for graph rendering\n",
        "print(\"‚è≥ Installing system packages for Graphviz...\")\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install -y graphviz > /dev/null\n",
        "print(\"‚úÖ System packages installed.\")\n",
        "\n",
        "# 2. Install all required Python libraries\n",
        "print(\"‚è≥ Installing Python libraries (autogen, gradio, groq, etc.)...\")\n",
        "!pip install \"pyautogen>=0.2.25\" \"duckduckgo-search>=5.3.1b1\" \"groq>=0.9.0\" \"gliclass>=0.2.1\" \"transformers\" \"torch\" \"sentence-transformers\" \"graphviz\" > /dev/null\n",
        "print(\"‚úÖ Python libraries installed.\")\n",
        "\n",
        "# 3. IMPORTANT: SET YOUR API KEY HERE\n",
        "# Replace the placeholder with your actual Groq API key\n",
        "GROQ_API_KEY = \"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\" # <--- REPLACE WITH YOUR KEY\n",
        "\n",
        "# 4. Environment and validation\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "\n",
        "if \"gsk_\" not in GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY is not set correctly. Please replace the placeholder with your key.\")\n",
        "else:\n",
        "    print(\"‚úÖ Groq API Key set successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq duckduckgo_search gliclass transformers torch sentence-transformers graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoMXaHUTALhM",
        "outputId": "c243a019-7905-4415-fd78-de1ae5951ec8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: duckduckgo_search in /usr/local/lib/python3.11/dist-packages (8.0.4)\n",
            "Requirement already satisfied: gliclass in /usr/local/lib/python3.11/dist-packages (0.1.11)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.21)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (8.2.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (5.4.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from gliclass) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gliclass) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->gliclass) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->gliclass) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyautogen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox_WxpmWBInH",
        "outputId": "54e6f738-4126-4781-b5eb-6c7adb15f7c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyautogen in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (4.9.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.0.8)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from pyautogen) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from pyautogen) (7.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pyautogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from pyautogen) (1.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (4.14.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->pyautogen) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->pyautogen) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->pyautogen) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: All Imports and Configurations\n",
        "\n",
        "# --- Standard & External Libs ---\n",
        "import ast\n",
        "import re\n",
        "import concurrent.futures\n",
        "from typing import List, Dict\n",
        "\n",
        "# --- Service/API Libs ---\n",
        "from groq import Groq\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "# --- AutoGen Core ---\n",
        "import autogen\n",
        "\n",
        "# --- GLiClass for Classification ---\n",
        "from gliclass import GLiClassModel, ZeroShotClassificationPipeline\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# --- Gradio & Graphviz for UI ---\n",
        "import gradio as gr\n",
        "import graphviz\n",
        "import time\n",
        "\n",
        "# --- LLM CONFIG (FOR AUTOGEN) ---\n",
        "llm_config = {\n",
        "    \"config_list\": [\n",
        "        {\n",
        "            \"model\": \"meta-llama/llama-4-maverick-17b-128e-instruct\",  # Llama3 8B is a good, fast choice on Groq\n",
        "            \"api_key\": os.environ.get(\"GROQ_API_KEY\"),\n",
        "            \"api_type\": \"groq\",\n",
        "        }\n",
        "    ],\n",
        "    \"cache_seed\": None,\n",
        "}\n",
        "\n",
        "# --- GRAPHVIZ CONFIG (FOR UI) ---\n",
        "NODE_IDS = {\n",
        "    \"human\": \"human_user\",\n",
        "    \"classifier\": \"classifier\",\n",
        "    \"coordinator_receives\": \"coord_receives\",\n",
        "    \"subtasks_list\": \"subtasks_list\",\n",
        "    \"create_subagents\": \"create_subagents\",\n",
        "    \"execute_parallel\": \"execute_parallel\",\n",
        "    \"collect_results\": \"collect_results\",\n",
        "    \"combine_results\": \"combine_results\",\n",
        "    \"final_output\": \"final_output\",\n",
        "    \"simple_responder\": \"simple_responder\",\n",
        "}\n",
        "\n",
        "STATUS_COLORS = {\n",
        "    \"pending\": \"#d3d3d3\",    # Light Gray\n",
        "    \"running\": \"#ffdd77\",    # Light Orange/Gold\n",
        "    \"completed\": \"#b2e5b2\",  # Light Green\n",
        "    \"human\": \"#ffc0cb\",      # Pink\n",
        "    \"skipped\": \"#f0f0f0\",    # Very Light Gray\n",
        "}"
      ],
      "metadata": {
        "id": "TTbNIoSW_xKB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_jZykzxecbV",
        "outputId": "47b227ed-9e4f-4d41-f804-dfcaba27ba49"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.6.15)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.14.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=5a56ce304c8e0fba2a545e1d5c717f9e85bffc3b79bb04e72c0c07f0373830ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Classifier Setup, Helper Functions, and Agent Tools\n",
        "\n",
        "# --- Imports for tools and classifier ---\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import ast\n",
        "import graphviz\n",
        "import autogen\n",
        "import requests\n",
        "import wikipedia\n",
        "import concurrent.futures\n",
        "from typing import List, Dict\n",
        "from duckduckgo_search import DDGS\n",
        "# CORRECTED: We only need the pipeline class from gliclass\n",
        "from gliclass import ZeroShotClassificationPipeline\n",
        "# CORRECTED: No longer need these specific imports for classifier setup\n",
        "# from gliclass import GLiClassModel\n",
        "# from transformers import AutoTokenizer\n",
        "\n",
        "# --- Helper to clean LLM output ---\n",
        "def extract_python_list_from_string(text: str) -> str:\n",
        "    \"\"\"Extracts a Python list from a string.\"\"\"\n",
        "    match = re.search(r'\\[[\\s\\S]*?\\]', text)\n",
        "    return match.group(0) if match else None\n",
        "\n",
        "# --- Classifier setup and execution ---\n",
        "def setup_classifier():\n",
        "    \"\"\"Sets up the zero-shot classification pipeline.\"\"\"\n",
        "    print(\"‚è≥ Setting up the zero-shot classifier model (this may take a minute)...\")\n",
        "    try:\n",
        "        # CORRECTED: Initialize the pipeline directly with the model name.\n",
        "        # This allows the library to handle loading the model, tokenizer, and config correctly.\n",
        "        model = GLiClassModel.from_pretrained(\"knowledgator/gliclass-large-v1.0\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"knowledgator/gliclass-large-v1.0\")\n",
        "        pipeline = ZeroShotClassificationPipeline(\n",
        "            model,\n",
        "            tokenizer,\n",
        "            classification_type='multi-label',\n",
        "            device='cpu'\n",
        "        )\n",
        "        print(\"‚úÖ Classifier setup complete.\")\n",
        "        return pipeline\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to setup classifier: {e}\")\n",
        "        return None\n",
        "\n",
        "def classify_query(pipeline: ZeroShotClassificationPipeline, query: str, labels: List[str]) -> Dict:\n",
        "    \"\"\"Classifies a query using the pipeline.\"\"\"\n",
        "    if not pipeline: return {\"label\": \"complex_research\", \"score\": 1.0}\n",
        "    # The pipeline call signature might differ slightly, but this is the common usage\n",
        "    results = pipeline(query, labels, threshold=0.5)\n",
        "\n",
        "    # gliclass pipeline might return a dict directly, not a list containing a dict\n",
        "    if isinstance(results, dict) and 'labels' in results and 'scores' in results:\n",
        "        if not results['labels']:\n",
        "            return {\"label\": \"complex_research\", \"score\": 0.0}\n",
        "        # Find the index of the highest score and get the corresponding label\n",
        "        max_score_index = results['scores'].index(max(results['scores']))\n",
        "        best_result = {\"label\": results['labels'][max_score_index], \"score\": results['scores'][max_score_index]}\n",
        "        return best_result\n",
        "    # Handle the original expected format just in case\n",
        "    elif isinstance(results, list) and results:\n",
        "         return max(results[0], key=lambda x: x[\"score\"]) if results[0] else {\"label\": \"complex_research\", \"score\": 0.0}\n",
        "    else:\n",
        "        return {\"label\": \"complex_research\", \"score\": 0.0}\n",
        "\n",
        "\n",
        "# --- Tool Definitions ---\n",
        "\n",
        "def wikipedia_search(query: str, sentences: int = 5) -> str:\n",
        "  \"\"\"\n",
        "  Fetches a summary from Wikipedia for a given search term.\n",
        "\n",
        "  Args:\n",
        "    query: The term to search for on Wikipedia.\n",
        "    sentences: The number of sentences to include in the summary. Defaults to 5.\n",
        "\n",
        "  Returns:\n",
        "    A string containing the summary, or an error message if an error occurred.\n",
        "  \"\"\"\n",
        "  print(f\"\\nüìö [Sub-agent Tool] Searching Wikipedia for: '{query}'\")\n",
        "  try:\n",
        "    summary = wikipedia.summary(query, sentences=sentences, auto_suggest=False)\n",
        "    return summary\n",
        "  except wikipedia.exceptions.PageError:\n",
        "    return f\"Error: Page '{query}' not found on Wikipedia.\"\n",
        "  except wikipedia.exceptions.DisambiguationError as e:\n",
        "    return f\"Error: Disambiguation error for '{query}'. Possible options: {e.options}\"\n",
        "  except Exception as e:\n",
        "    return f\"An unexpected error occurred with Wikipedia search: {e}\"\n",
        "\n",
        "def langsearch_web_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Performs a web search using the LangSearch API to get up-to-date information.\n",
        "\n",
        "    Args:\n",
        "        query: The search query.\n",
        "\n",
        "    Returns:\n",
        "        A formatted string of search results or an error message.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüåê [Sub-agent Tool] Searching LangSearch for: '{query}'\")\n",
        "    url = \"https://api.langsearch.com/v1/web-search\"\n",
        "    payload = json.dumps({\n",
        "      \"query\": query,\n",
        "      \"freshness\": \"noLimit\",\n",
        "      \"summary\": True,\n",
        "      \"count\": 5  # Limit to 5 results for brevity\n",
        "    })\n",
        "    headers = {\n",
        "      'Authorization': 'sk-975b5afab002431a99a9dd24863f55da', # As provided\n",
        "      'Content-Type': 'application/json'\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, data=payload, timeout=15)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if \"data\" in data and \"webPages\" in data[\"data\"] and \"value\" in data[\"data\"][\"webPages\"]:\n",
        "            results = data[\"data\"][\"webPages\"][\"value\"]\n",
        "            if not results:\n",
        "                return f\"No results found for '{query}' via LangSearch.\"\n",
        "\n",
        "            output = [f\"Title: {r.get('name', 'No Title')}\\nSnippet: {r.get('snippet', 'No Snippet')}\" for r in results]\n",
        "            return \"\\n\\n\".join(output)\n",
        "        else:\n",
        "            return f\"LangSearch returned an unexpected response format for '{query}'.\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error during LangSearch for '{query}': {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with LangSearch: {e}\"\n",
        "\n",
        "def duckduckgo_search(query: str) -> str:\n",
        "    \"\"\"Performs a web search using DuckDuckGo.\"\"\"\n",
        "    print(f\"\\nüîé [Sub-agent Tool] Searching DuckDuckGo for: '{query}'\")\n",
        "    try:\n",
        "        with DDGS() as ddgs:\n",
        "            results = [r for r in ddgs.text(query, max_results=5)]\n",
        "            return \"\\n\\n\".join(f\"Title: {r['title']}\\nSnippet: {r['body']}\" for r in results) if results else f\"No results found for '{query}'.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error during DuckDuckGo search for '{query}': {e}\"\n",
        "\n",
        "# --- Setup the classifier once globally ---\n",
        "CLASSIFIER_PIPELINE = setup_classifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4iwamk0eVKQ",
        "outputId": "30a7be21-44f5-437c-c4f3-aa5c09140400"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Setting up the zero-shot classifier model (this may take a minute)...\n",
            "‚úÖ Classifier setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Integrated Agentic Workflow with Visualization Hooks\n",
        "\n",
        "def create_graph_image(statuses, num_subtasks=0, temp_dir='gradio_temp'):\n",
        "    \"\"\"Generates and saves a Graphviz image based on current node statuses.\"\"\"\n",
        "    if not os.path.exists(temp_dir): os.makedirs(temp_dir)\n",
        "\n",
        "    dot = graphviz.Digraph(comment='Live Agentic Process')\n",
        "    dot.attr(rankdir='TB', splines='ortho')\n",
        "    dot.node_attr['style'] = 'filled'\n",
        "    # Define all nodes first\n",
        "    dot.node(NODE_IDS[\"human\"], '1. Human User', shape='box', fillcolor=statuses[NODE_IDS[\"human\"]])\n",
        "    dot.node(NODE_IDS[\"classifier\"], '2. Classify Query', shape='ellipse', fillcolor=statuses[NODE_IDS[\"classifier\"]])\n",
        "    # Complex Path\n",
        "    dot.node(NODE_IDS[\"coordinator_receives\"], '3a. Coordinator Receives Task', shape='box', fillcolor=statuses[NODE_IDS[\"coordinator_receives\"]])\n",
        "    dot.node(NODE_IDS[\"subtasks_list\"], '4a. Create Subtasks List', shape='note', fillcolor=statuses[NODE_IDS[\"subtasks_list\"]])\n",
        "    dot.node(NODE_IDS[\"create_subagents\"], '5a. Create Sub-agents', shape='box', fillcolor=statuses[NODE_IDS[\"create_subagents\"]])\n",
        "    dot.node(NODE_IDS[\"execute_parallel\"], '6a. Execute in Parallel', shape='diamond', fillcolor=statuses[NODE_IDS[\"execute_parallel\"]])\n",
        "    for i in range(1, num_subtasks + 1):\n",
        "        dot.node(f\"sub_agent_{i}\", f'Sub-agent {i}', shape='box', fillcolor=statuses.get(f\"sub_agent_{i}\", STATUS_COLORS['pending']))\n",
        "    dot.node(NODE_IDS[\"collect_results\"], '7a. Collect Results', shape='box', fillcolor=statuses[NODE_IDS[\"collect_results\"]])\n",
        "    dot.node(NODE_IDS[\"combine_results\"], '8a. Combine Results', shape='box', fillcolor=statuses[NODE_IDS[\"combine_results\"]])\n",
        "    # Simple Path\n",
        "    dot.node(NODE_IDS[\"simple_responder\"], '3b. Simple Responder', shape='box', fillcolor=statuses[NODE_IDS[\"simple_responder\"]])\n",
        "    # Final Output\n",
        "    dot.node(NODE_IDS[\"final_output\"], '9. Generate Final Output', shape='box', fillcolor=statuses[NODE_IDS[\"final_output\"]])\n",
        "\n",
        "    # Define Edges\n",
        "    dot.edge(NODE_IDS[\"human\"], NODE_IDS[\"classifier\"])\n",
        "    dot.edge(NODE_IDS[\"classifier\"], NODE_IDS[\"coordinator_receives\"], label='Complex')\n",
        "    dot.edge(NODE_IDS[\"classifier\"], NODE_IDS[\"simple_responder\"], label='Simple')\n",
        "    dot.edge(NODE_IDS[\"coordinator_receives\"], NODE_IDS[\"subtasks_list\"])\n",
        "    dot.edge(NODE_IDS[\"subtasks_list\"], NODE_IDS[\"create_subagents\"])\n",
        "    dot.edge(NODE_IDS[\"create_subagents\"], NODE_IDS[\"execute_parallel\"])\n",
        "    for i in range(1, num_subtasks + 1):\n",
        "        dot.edge(NODE_IDS[\"execute_parallel\"], f\"sub_agent_{i}\")\n",
        "        dot.edge(f\"sub_agent_{i}\", NODE_IDS[\"collect_results\"])\n",
        "    dot.edge(NODE_IDS[\"collect_results\"], NODE_IDS[\"combine_results\"])\n",
        "    dot.edge(NODE_IDS[\"combine_results\"], NODE_IDS[\"final_output\"])\n",
        "    dot.edge(NODE_IDS[\"simple_responder\"], NODE_IDS[\"final_output\"])\n",
        "\n",
        "    output_path = os.path.join(temp_dir, 'graph')\n",
        "    dot.render(output_path, format='png', cleanup=True)\n",
        "    return f\"{output_path}.png\"\n",
        "\n",
        "\n",
        "\n",
        "def run_subtask(subtask: str, worker_agent: autogen.AssistantAgent) -> str:\n",
        "    \"\"\"\n",
        "    Helper to run a single sub-task with all tools registered.\n",
        "    This version is robust against agents ending on a tool call.\n",
        "    \"\"\"\n",
        "    print(f\"  üßµ [Thread] Starting task for {worker_agent.name}: '{subtask}'\")\n",
        "    thread_proxy = autogen.UserProxyAgent(name=f\"Proxy_{worker_agent.name}\", human_input_mode=\"NEVER\", code_execution_config=False)\n",
        "\n",
        "    # Register all available tools for the sub-agent\n",
        "    autogen.register_function(\n",
        "        duckduckgo_search,\n",
        "        caller=worker_agent, executor=thread_proxy, name=\"duckduckgo_search\",\n",
        "        description=\"Performs a web search using DuckDuckGo. Use for general-purpose searches, current events, or when other tools fail.\"\n",
        "    )\n",
        "    autogen.register_function(\n",
        "        wikipedia_search,\n",
        "        caller=worker_agent, executor=thread_proxy, name=\"wikipedia_search\",\n",
        "        description=\"Fetches a concise summary from Wikipedia. Best for well-defined entities like people, places, organizations, or historical events.\"\n",
        "    )\n",
        "    autogen.register_function(\n",
        "        langsearch_web_search,\n",
        "        caller=worker_agent, executor=thread_proxy, name=\"langsearch_web_search\",\n",
        "        description=\"Performs a web search using the LangSearch API to get a summarized list of results. Good for broad research queries.\"\n",
        "    )\n",
        "\n",
        "    thread_proxy.initiate_chat(worker_agent, message=subtask, max_turns=5, silent=False)\n",
        "\n",
        "    # --- ROBUSTNESS FIX STARTS HERE ---\n",
        "    final_message = thread_proxy.last_message(worker_agent)\n",
        "\n",
        "    # Check if a final message exists and has content.\n",
        "    if final_message and isinstance(final_message.get(\"content\"), str) and final_message[\"content\"].strip():\n",
        "        result = final_message[\"content\"]\n",
        "        print(f\"  ‚úÖ [Thread] Finished task for {worker_agent.name}.\")\n",
        "        return result\n",
        "    else:\n",
        "        # If the agent ends on a tool call or produces no content, provide a default response.\n",
        "        print(f\"  ‚ö†Ô∏è [Thread] Sub-agent {worker_agent.name} did not produce a final text response. Returning a default message.\")\n",
        "        return f\"Sub-agent {worker_agent.name} completed its search for '{subtask}' but did not provide a summary.\"\n",
        "    # --- ROBUSTNESS FIX ENDS HERE ---\n",
        "\n",
        "def run_full_process(user_query: str):\n",
        "    \"\"\"The main generator function that runs the whole process and yields UI updates.\"\"\"\n",
        "    log = \"\"\n",
        "    statuses = {node_id: STATUS_COLORS['pending'] for node_id in NODE_IDS.values()}\n",
        "    statuses[NODE_IDS[\"human\"]] = STATUS_COLORS['human']\n",
        "\n",
        "    # --- Initial State ---\n",
        "    log += \"Process started. Waiting for user input...\\n\"\n",
        "    yield create_graph_image(statuses), log\n",
        "\n",
        "    # --- Phase 1: Classification ---\n",
        "    statuses[NODE_IDS[\"classifier\"]] = STATUS_COLORS['running']\n",
        "    log += f\"\\n--- [Phase 1/2] Classifying Query ---\\nQuery: '{user_query}'\\n\"\n",
        "    yield create_graph_image(statuses), log\n",
        "    time.sleep(1)\n",
        "\n",
        "    labels = [\"trivial\", \"non-trivial\", \"greetings\", \"alphabets\",\"letters\",\"symbols\",\"numbers\",\"greetings\",\"research\",\"technology\"]\n",
        "    best_label_info = classify_query(CLASSIFIER_PIPELINE, user_query, labels)\n",
        "    best_label = best_label_info['label']\n",
        "    statuses[NODE_IDS[\"classifier\"]] = STATUS_COLORS['completed']\n",
        "    log += f\"üìä Query classified as: '{best_label}' with score {best_label_info['score']:.2f}.\\n\"\n",
        "    yield create_graph_image(statuses), log\n",
        "    time.sleep(1)\n",
        "\n",
        "    # --- Phase 2: Execution (Two Paths) ---\n",
        "    if best_label in [\"trivial\", \"greetings\",\"alphabets\",\"letters\",\"symbols\",\"numbers\"]:\n",
        "        # --- SIMPLE WORKFLOW ---\n",
        "        log += \"\\n--- [Phase 2/2] Executing Simple Q&A Workflow ---\\n\"\n",
        "        statuses[NODE_IDS[\"simple_responder\"]] = STATUS_COLORS['running']\n",
        "        yield create_graph_image(statuses), log\n",
        "\n",
        "        simple_responder = autogen.AssistantAgent(name=\"SimpleResponder\", llm_config=llm_config, system_message=\"You are a helpful AI assistant. Answer the user's query directly and concisely. If the query is a greeting, respond politely.\")\n",
        "        proxy = autogen.UserProxyAgent(name=\"UserProxy\", human_input_mode=\"NEVER\")\n",
        "        proxy.initiate_chat(simple_responder, message=user_query, max_turns=1, silent=True)\n",
        "        final_response = proxy.last_message(simple_responder)[\"content\"]\n",
        "\n",
        "        statuses[NODE_IDS[\"simple_responder\"]] = STATUS_COLORS['completed']\n",
        "        statuses[NODE_IDS[\"final_output\"]] = STATUS_COLORS['running']\n",
        "        yield create_graph_image(statuses), log\n",
        "        time.sleep(1)\n",
        "        statuses[NODE_IDS[\"final_output\"]] = STATUS_COLORS['completed']\n",
        "        log += f\"\\n‚úÖ FINAL RESPONSE:\\n\\n{final_response}\\n\"\n",
        "        yield create_graph_image(statuses), log\n",
        "\n",
        "    else:\n",
        "        # --- COMPLEX WORKFLOW ---\n",
        "        num_subtasks = 0\n",
        "\n",
        "        # Coordinator\n",
        "        statuses[NODE_IDS[\"coordinator_receives\"]] = STATUS_COLORS['running']\n",
        "        log += \"\\n--- [Phase 2/6] Coordinator: Breaking down task... ---\\n\"\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "        coordinator = autogen.AssistantAgent(name=\"Coordinator\", llm_config=llm_config, system_message=f\"You are a master coordinator. Break down the user's query into 4 smaller, independent sub-tasks for web research. Respond with ONLY a Python-parseable list of strings.\\nUser Query: \\\"{user_query}\\\"\")\n",
        "        proxy = autogen.UserProxyAgent(name=\"MainProxy\", human_input_mode=\"NEVER\")\n",
        "        proxy.initiate_chat(coordinator, message=f\"Break down this query: {user_query}\", max_turns=1, silent=True)\n",
        "        subtasks_response = proxy.last_message(coordinator)[\"content\"]\n",
        "        statuses[NODE_IDS[\"coordinator_receives\"]] = STATUS_COLORS['completed']\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "\n",
        "        # Subtask List Creation\n",
        "        statuses[NODE_IDS[\"subtasks_list\"]] = STATUS_COLORS['running']\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "        subtasks = []\n",
        "        try:\n",
        "            list_string = extract_python_list_from_string(subtasks_response)\n",
        "            subtasks = ast.literal_eval(list_string) if list_string else [user_query]\n",
        "        except:\n",
        "            subtasks = [user_query]\n",
        "        num_subtasks = len(subtasks)\n",
        "        log += f\"‚úÖ Coordinator generated {num_subtasks} subtasks: {subtasks}\\n\"\n",
        "        statuses[NODE_IDS[\"subtasks_list\"]] = STATUS_COLORS['completed']\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "\n",
        "        # Create & Execute Sub-agents\n",
        "        statuses[NODE_IDS[\"create_subagents\"]] = STATUS_COLORS['running']\n",
        "        log += \"\\n--- [Phase 3/6] Creating & Executing Sub-agents... ---\\n\"\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "        time.sleep(1)\n",
        "        statuses[NODE_IDS[\"create_subagents\"]] = STATUS_COLORS['completed']\n",
        "        statuses[NODE_IDS[\"execute_parallel\"]] = STATUS_COLORS['running']\n",
        "        for i in range(1, num_subtasks + 1): statuses[f\"sub_agent_{i}\"] = STATUS_COLORS['running']\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "\n",
        "        # UPDATED System message for worker agents\n",
        "        worker_system_message = \"\"\"You are a research agent. You have access to three tools:\n",
        "1. `wikipedia_search`: Best for well-defined topics (e.g., \"Eiffel Tower\", \"Albert Einstein\").\n",
        "2. `duckduckgo_search`: Best for general web searches, opinions, or very current events.\n",
        "3. `langsearch_web_search`: Best for broad research questions that benefit from summarized results from multiple sources.\n",
        "\n",
        "Based on your given sub-task, choose the single most appropriate tool, execute it, and then formulate a comprehensive answer based ONLY on the tool's output. Respond with the final answer directly.\"\"\"\n",
        "\n",
        "        worker_agents = [autogen.AssistantAgent(name=f\"Sub_Agent_{i+1}\", llm_config=llm_config, system_message=worker_system_message) for i in range(num_subtasks)]\n",
        "        results = []\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_subtasks) as executor:\n",
        "            future_to_task = {executor.submit(run_subtask, task, agent): task for agent, task in zip(worker_agents, subtasks)}\n",
        "            for future in concurrent.futures.as_completed(future_to_task):\n",
        "                try: results.append(future.result())\n",
        "                except Exception as e: results.append(f\"Error processing subtask: {e}\")\n",
        "\n",
        "        log += \"‚úÖ All sub-agent threads have completed.\\n\"\n",
        "        statuses[NODE_IDS[\"execute_parallel\"]] = STATUS_COLORS['completed']\n",
        "        for i in range(1, num_subtasks + 1): statuses[f\"sub_agent_{i}\"] = STATUS_COLORS['completed']\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "\n",
        "        # Collect & Combine Results\n",
        "        for node_id, phase_name in [(NODE_IDS[\"collect_results\"], \"Collecting\"), (NODE_IDS[\"combine_results\"], \"Synthesizing\")]:\n",
        "            statuses[node_id] = STATUS_COLORS['running']\n",
        "            log += f\"\\n--- [Phase {4 if node_id == NODE_IDS['collect_results'] else 5}/6] {phase_name} Results... ---\\n\"\n",
        "            yield create_graph_image(statuses, num_subtasks), log\n",
        "            time.sleep(1)\n",
        "            statuses[node_id] = STATUS_COLORS['completed']\n",
        "            yield create_graph_image(statuses, num_subtasks), log\n",
        "\n",
        "        # Final Output\n",
        "        statuses[NODE_IDS[\"final_output\"]] = STATUS_COLORS['running']\n",
        "        log += \"\\n--- [Phase 6/6] Generating Final Output... ---\\n\"\n",
        "        yield create_graph_image(statuses, num_subtasks), log\n",
        "        synthesizer = autogen.AssistantAgent(name=\"Synthesizer\", llm_config=llm_config, system_message=\"You are a master report writer. Synthesize results from sub-agents into a single, cohesive, final answer.\")\n",
        "        combined_results = \"\\n\\n\".join(results)\n",
        "        synthesis_message = f\"Original query: \\\"{user_query}\\\"\\n\\nResults from sub-tasks:\\n{combined_results}\\n\\nSynthesize these into a final, well-structured answer.\"\n",
        "        proxy.initiate_chat(synthesizer, message=synthesis_message, max_turns=1, silent=True)\n",
        "        final_response = proxy.last_message(synthesizer)[\"content\"]\n",
        "\n",
        "        statuses[NODE_IDS[\"final_output\"]] = STATUS_COLORS['completed']\n",
        "        log += f\"\\n‚úÖ FINAL RESPONSE:\\n\\n{final_response}\\n\"\n",
        "        yield create_graph_image(statuses, num_subtasks), log"
      ],
      "metadata": {
        "id": "mqg1Y20Cfd98"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Build and Launch the Gradio UI\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Live Agentic Workflow\") as demo:\n",
        "    gr.Markdown(\"# Live Visualization of an AutoGen Agentic Workflow\")\n",
        "    gr.Markdown(\"Enter a query below. The system will classify it, choose a workflow (Simple Q&A or Complex Research), and visualize the process live.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        query_input = gr.Textbox(\n",
        "            label=\"Your Query\",\n",
        "            placeholder=\"e.g., What were the key findings of the Llama 3 paper?\",\n",
        "            scale=3\n",
        "        )\n",
        "        start_button = gr.Button(\"‚ñ∂Ô∏è Start Process\", variant=\"primary\", scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        graph_output = gr.Image(label=\"Process Flowchart\", type=\"filepath\", height=700, interactive=False)\n",
        "        log_output = gr.Textbox(label=\"Process Log & Final Answer\", lines=25, interactive=False)\n",
        "\n",
        "    # Connect the button to the main workflow function\n",
        "    start_button.click(\n",
        "        fn=run_full_process,\n",
        "        inputs=[query_input],\n",
        "        outputs=[graph_output, log_output]\n",
        "    )\n",
        "\n",
        "    # Add examples for users to try\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"Hello, how are you?\",\n",
        "            \"What is the capital of France?\",\n",
        "            \"Compare the pros and cons of using React vs. Vue for a new web project.\",\n",
        "            \"What are the latest advancements in treating Alzheimer's disease?\",\n",
        "        ],\n",
        "        inputs=query_input\n",
        "    )\n",
        "\n",
        "# Launch the app - share=True is essential for Google Colab\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w6tu_esu_7e4",
        "outputId": "d9288979-d801-47b9-ff6c-f6af0c7b1045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://82d40337530c776972.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://82d40337530c776972.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.62s/it]\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>> TERMINATING RUN (67bd9882-b780-461e-897b-b15b870b46e8): Maximum turns (1) reached\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/autogen/oai/groq.py:303: UserWarning: Cost calculation not available for model meta-llama/llama-4-maverick-17b-128e-instruct\n",
            "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  üßµ [Thread] Starting task for Sub_Agent_1: 'Identify pros of using React for web development'\n",
            "Proxy_Sub_Agent_1 (to Sub_Agent_1):\n",
            "\n",
            "Identify pros of using React for web development\n",
            "  üßµ [Thread] Starting task for Sub_Agent_2: 'Identify cons of using React for web development'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "  üßµ [Thread] Starting task for Sub_Agent_3: 'Identify pros of using Vue for web development'\n",
            "Proxy_Sub_Agent_2 (to Sub_Agent_2):\n",
            "\n",
            "  üßµ [Thread] Starting task for Sub_Agent_4: 'Identify cons of using Vue for web development'\n",
            "Identify cons of using React for web development\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_3 (to Sub_Agent_3):\n",
            "\n",
            "Identify pros of using Vue for web development\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_4 (to Sub_Agent_4):\n",
            "\n",
            "Identify cons of using Vue for web development\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_1 (to Proxy_Sub_Agent_1):\n",
            "\n",
            "***** Suggested tool call (82yzpewm7): langsearch_web_search *****\n",
            "Arguments: \n",
            "{\"query\":\"pros of using React for web development\"}\n",
            "******************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION langsearch_web_search...\n",
            "Call ID: 82yzpewm7\n",
            "Input arguments: {'query': 'pros of using React for web development'}\n",
            "\n",
            "üåê [Sub-agent Tool] Searching LangSearch for: 'pros of using React for web development'\n",
            "Sub_Agent_2 (to Proxy_Sub_Agent_2):\n",
            "\n",
            "Sub_Agent_3 (to Proxy_Sub_Agent_3):\n",
            "\n",
            "***** Suggested tool call (d1bvay0fd): langsearch_web_search *****\n",
            "Arguments: \n",
            "{\"query\":\"pros of using Vue for web development\"}\n",
            "******************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION langsearch_web_search...\n",
            "Call ID: d1bvay0fd\n",
            "Input arguments: {'query': 'pros of using Vue for web development'}\n",
            "\n",
            "üåê [Sub-agent Tool] Searching LangSearch for: 'pros of using Vue for web development'\n",
            "***** Suggested tool call (9sxqxvq2v): langsearch_web_search *****\n",
            "Arguments: \n",
            "{\"query\":\"cons of using React for web development\"}\n",
            "******************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION langsearch_web_search...\n",
            "Call ID: 9sxqxvq2v\n",
            "Input arguments: {'query': 'cons of using React for web development'}\n",
            "\n",
            "üåê [Sub-agent Tool] Searching LangSearch for: 'cons of using React for web development'\n",
            "Sub_Agent_4 (to Proxy_Sub_Agent_4):\n",
            "\n",
            "***** Suggested tool call (d14p8nzez): langsearch_web_search *****\n",
            "Arguments: \n",
            "{\"query\":\"cons of using Vue for web development\"}\n",
            "******************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION langsearch_web_search...\n",
            "Call ID: d14p8nzez\n",
            "Input arguments: {'query': 'cons of using Vue for web development'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/autogen/oai/groq.py:303: UserWarning: Cost calculation not available for model meta-llama/llama-4-maverick-17b-128e-instruct\n",
            "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üåê [Sub-agent Tool] Searching LangSearch for: 'cons of using Vue for web development'\n",
            "Proxy_Sub_Agent_3 (to Sub_Agent_3):\n",
            "\n",
            "***** Response from calling tool (d1bvay0fd) *****\n",
            "Error during LangSearch for 'pros of using Vue for web development': 429 Client Error:  for url: https://api.langsearch.com/v1/web-search\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_2 (to Sub_Agent_2):\n",
            "\n",
            "***** Response from calling tool (9sxqxvq2v) *****\n",
            "Proxy_Sub_Agent_1 (to Sub_Agent_1):\n",
            "\n",
            "***** Response from calling tool (82yzpewm7) *****\n",
            "Error during LangSearch for 'cons of using React for web development': 429 Client Error:  for url: https://api.langsearch.com/v1/web-search\n",
            "Error during LangSearch for 'pros of using React for web development': 429 Client Error:  for url: https://api.langsearch.com/v1/web-search\n",
            "**************************************************\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_2 (to Proxy_Sub_Agent_2):\n",
            "\n",
            "***** Suggested tool call (3p5jc0wbf): duckduckgo_search *****\n",
            "Arguments: \n",
            "{\"query\":\"disadvantages of React for web development\"}\n",
            "**************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION duckduckgo_search...\n",
            "Call ID: 3p5jc0wbf\n",
            "Input arguments: {'query': 'disadvantages of React for web development'}\n",
            "\n",
            "üîé [Sub-agent Tool] Searching DuckDuckGo for: 'disadvantages of React for web development'\n",
            "Sub_Agent_3 (to Proxy_Sub_Agent_3):\n",
            "\n",
            "Vue.js is a popular JavaScript framework for building user interfaces and single-page applications. Some of the key pros of using Vue for web development include its simplicity, flexibility, and robust ecosystem. It offers a more gradual learning curve compared to other frameworks like React or Angular, making it more accessible to developers. Vue's component-based architecture promotes reusability and maintainability of code. Additionally, Vue's robust ecosystem, including tools like Vue CLI, Vue Router, and Vuex, provides a comprehensive solution for managing complex applications. Its strong community support and extensive documentation further enhance its appeal for web development projects.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_3 (to Sub_Agent_3):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_1 (to Proxy_Sub_Agent_1):\n",
            "\n",
            "React is a popular JavaScript library for building user interfaces and can be used for developing complex web applications. Some benefits of using React include:\n",
            "\n",
            "1. Component-based architecture: React's component-based architecture makes it easier to manage and maintain complex UIs by breaking them down into smaller, reusable components.\n",
            "\n",
            "However, I couldn't get the full list of pros due to an error with the search service. For more information, you may try searching online or checking React's official documentation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_1 (to Sub_Agent_1):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_2 (to Sub_Agent_2):\n",
            "\n",
            "***** Response from calling tool (3p5jc0wbf) *****\n",
            "Error during DuckDuckGo search for 'disadvantages of React for web development': https://html.duckduckgo.com/html 202 Ratelimit\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_4 (to Sub_Agent_4):\n",
            "\n",
            "***** Response from calling tool (d14p8nzez) *****\n",
            "Title: The Pros and Cons of Vue.js | AltexSoft\n",
            "Snippet: the good and the bad of vue.js framework programming \n",
            " contents \n",
            " what is vue.js \n",
            " vue.js tooling and ecosystem \n",
            " the pros of vue.js \n",
            " tiny size \n",
            " virtual dom rendering and performance \n",
            " reactivity sy...\n",
            "\n",
            "Title: What Are The Pros And Cons Of Using Vue.js For Web Development\n",
            "Snippet: what is vue . js ? vue.js pros and cons : a complete guide \n",
            " table of content \n",
            " summary \n",
            " what is vue . js ? \n",
            " pros of using vue.js for web development \n",
            " ease of learning and integration \n",
            " flexibility...\n",
            "\n",
            "Title: The Pros and Cons of Vue.js\n",
            "Snippet: the good and the bad of vue.js framework programming \n",
            " engineering \n",
            " while javascript is fully - fledged on its own , its ecosystem means even more than the language itself . tools like frameworks mak...\n",
            "\n",
            "Title: Using Vue: Pros and Cons - The Codest\n",
            "Snippet: software development \n",
            " using vue : pros and cons \n",
            " today ‚Äôs front end development is much improved by frameworks that provide basis and tools , making this process much easier and smoother . it ‚Äôs lik...\n",
            "\n",
            "Title: Pros And Cons Of Using Vue.js for Web Development | Nordic APIs |\n",
            "Snippet: pros and cons of using vue.js for web development \n",
            " javascript has provided a perfect ecosystem to the technology industry in recent years , made possible by popular js frameworks like node , vue , re...\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_3 (to Proxy_Sub_Agent_3):\n",
            "\n",
            "It seems like your response was cut off. If you're looking for more information on Vue.js or have a specific question about its use in web development, feel free to ask!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_3 (to Sub_Agent_3):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_1 (to Proxy_Sub_Agent_1):\n",
            "\n",
            "It seems like you were about to ask something else. You can go ahead and ask your question, and I'll be happy to help.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_1 (to Sub_Agent_1):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_1 (to Proxy_Sub_Agent_1):\n",
            "\n",
            "It seems like you're not asking a question. If you need information or have a query, feel free to ask, and I'll do my best to provide a helpful response.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_1 (to Sub_Agent_1):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_1 (to Proxy_Sub_Agent_1):\n",
            "\n",
            "It seems you're not asking a question. If you need assistance or have a query, I'm here to help. You can ask me anything, and I'll do my best to provide a helpful response.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (14f19d33-0a00-4ae9-8cec-3aacdbd1ce04): Maximum turns (5) reached\n",
            "  ‚úÖ [Thread] Finished task for Sub_Agent_1.\n",
            "Sub_Agent_3 (to Proxy_Sub_Agent_3):\n",
            "\n",
            "It seems like you're trying to continue a conversation, but there's no text. If you have a question or need information on Vue.js or web development, I'm here to help.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Proxy_Sub_Agent_3 (to Sub_Agent_3):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Sub_Agent_3 (to Proxy_Sub_Agent_3):\n",
            "\n",
            "It seems there's no text to respond to. If you have a question or need help with Vue.js or any other topic, feel free to ask, and I'll do my best to assist you.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (0074754b-d6c4-4872-b366-a63a9d3b7cbc): Maximum turns (5) reached\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚úÖ [Thread] Finished task for Sub_Agent_3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>> TERMINATING RUN (55fb8755-bb0b-4aff-b2e0-77bda7fea8f5): Maximum turns (1) reached\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/autogen/oai/groq.py:303: UserWarning: Cost calculation not available for model meta-llama/llama-4-maverick-17b-128e-instruct\n",
            "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n",
            "Warning: Orthogonal edges do not currently handle edge labels. Try using xlabels.\n"
          ]
        }
      ]
    }
  ]
}