{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Donut by Hugging Face"
      ],
      "metadata": {
        "id": "8uolNx_6my3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers pytorch-lightning pdf2image pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z-CwoOZwm2ZV",
        "outputId": "4674f821-c3d1-4ff5-f261-8d566688b505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.0.post0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.5.1+cu124)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "import torch\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "mUX6CPrWm6A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UZssIFuTm8a1",
        "outputId": "2f14e10b-a8ff-4d5b-e0e3-087b4106752c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Config of the encoder: <class 'transformers.models.donut.modeling_donut_swin.DonutSwinModel'> is overwritten by shared encoder config: DonutSwinConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"depths\": [\n",
            "    2,\n",
            "    2,\n",
            "    14,\n",
            "    2\n",
            "  ],\n",
            "  \"drop_path_rate\": 0.1,\n",
            "  \"embed_dim\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"image_size\": [\n",
            "    2560,\n",
            "    1920\n",
            "  ],\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"mlp_ratio\": 4.0,\n",
            "  \"model_type\": \"donut-swin\",\n",
            "  \"num_channels\": 3,\n",
            "  \"num_heads\": [\n",
            "    4,\n",
            "    8,\n",
            "    16,\n",
            "    32\n",
            "  ],\n",
            "  \"num_layers\": 4,\n",
            "  \"patch_size\": 4,\n",
            "  \"path_norm\": true,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_absolute_embeddings\": false,\n",
            "  \"window_size\": 10\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.mbart.modeling_mbart.MBartForCausalLM'> is overwritten by shared decoder config: MBartConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 4,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"max_position_embeddings\": 1536,\n",
            "  \"model_type\": \"mbart\",\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": true,\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 57525\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionEncoderDecoderModel(\n",
              "  (encoder): DonutSwinModel(\n",
              "    (embeddings): DonutSwinEmbeddings(\n",
              "      (patch_embeddings): DonutSwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): DonutSwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): Identity()\n",
              "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.005263158120214939)\n",
              "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.010526316240429878)\n",
              "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.015789475291967392)\n",
              "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.021052632480859756)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.02631578966975212)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (2): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.031578950583934784)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (3): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.03684210777282715)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (4): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.04210526496171951)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (5): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.04736842215061188)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (6): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.05263157933950424)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (7): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.057894736528396606)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (8): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.06315789371728897)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (9): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.06842105090618134)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (10): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.0736842080950737)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (11): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.07894736528396606)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (12): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.08421052992343903)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (13): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.08947368711233139)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.09473684430122375)\n",
              "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.10000000149011612)\n",
              "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (decoder): MBartForCausalLM(\n",
              "    (model): MBartDecoderWrapper(\n",
              "      (decoder): MBartDecoder(\n",
              "        (embed_tokens): MBartScaledWordEmbedding(57525, 1024, padding_idx=1)\n",
              "        (embed_positions): MBartLearnedPositionalEmbedding(1538, 1024)\n",
              "        (layers): ModuleList(\n",
              "          (0-3): 4 x MBartDecoderLayer(\n",
              "            (self_attn): MBartSdpaAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (activation_fn): GELUActivation()\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (encoder_attn): MBartSdpaAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (lm_head): Linear(in_features=1024, out_features=57525, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Poppler (Required for pdf2image)\n",
        "!apt-get install -y poppler-utils\n",
        "\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "\n",
        "# pdf_path = \"/content/Screenshot 2025-02-14 115920.png\"  # Replace with your actual PDF file\n",
        "# # images = convert_from_path(pdf_path)\n",
        "# images = \"/content\"\n",
        "\n",
        "# # Save images from PDF\n",
        "# image_paths = []\n",
        "# for i, image in enumerate(images):\n",
        "#     img_path = f\"page_{i}.png\"\n",
        "#     image.save(img_path, \"PNG\")\n",
        "#     image_paths.append(img_path)\n",
        "\n",
        "# print(\"PDF successfully converted to images:\", image_paths)\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# Use the existing image directly\n",
        "image_paths = [\"/content/sample_data/Screenshot 2025-02-14 115920.png\"]  # Add image paths here\n",
        "\n",
        "print(\"Using images directly:\", image_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNZ6v3xrm-qD",
        "outputId": "efc6df97-1fff-4573-c278-0539e58aafa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Using images directly: ['/content/sample_data/Screenshot 2025-02-14 115920.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# import torch\n",
        "\n",
        "def read_pdf_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "\n",
        "    # Get decoder start token ID\n",
        "    decoder_start_token_id = model.config.decoder_start_token_id or model.config.bos_token_id or 0\n",
        "    decoder_input_ids = torch.tensor([[decoder_start_token_id]]).to(device)\n",
        "\n",
        "    # Generate text\n",
        "    outputs = model.generate(pixel_values, decoder_input_ids=decoder_input_ids, max_length=512)\n",
        "    generated_text = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Save extracted text to a file\n",
        "output_file = \"extracted_text.txt\"\n",
        "\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for img_path in image_paths:\n",
        "        print(f\"Reading: {img_path}\")\n",
        "        extracted_text = read_pdf_image(img_path)\n",
        "        f.write(f\"=== Extracted Text from {img_path} ===\\n\")\n",
        "        f.write(extracted_text + \"\\n\\n\")  # Add spacing between pages\n",
        "\n",
        "print(f\"Extracted text saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YQQBEuRnBNC",
        "outputId": "de645f2e-cfcc-420a-ca3c-5533db2079f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Legacy behavior is being used. The current behavior will be deprecated in version 5.0.0. In the new behavior, if both images and text are provided, the default value of `add_special_tokens` will be changed to `False` when calling the tokenizer if `add_special_tokens` is unset. To test the new behavior, set `legacy=False`as a processor call argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading: /content/sample_data/Screenshot 2025-02-14 115920.png\n",
            "Extracted text saved to extracted_text.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using TrOCR by Hugging face"
      ],
      "metadata": {
        "id": "HGpCPR6btRc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "\n",
        "# Load TrOCR model\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "\n",
        "# Load image from local file path\n",
        "image_path = \"/content/sample_data/Screenshot 2025-02-14 115920.png\"  # Replace with the correct path\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Process the image\n",
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "generated_ids = model.generate(pixel_values)\n",
        "\n",
        "# Decode the text\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"Extracted Text:\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cReXPsIytY4p",
        "outputId": "d579e9d8-e25c-4ca4-f9d7-8d2b240e5042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": false,\n",
            "  \"transformers_version\": \"4.48.3\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"cross_attention_hidden_size\": 768,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layernorm_embedding\": true,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"trocr\",\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_learned_position_embeddings\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text: 0 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using PaliGemma 3b-pt by Hugging Face"
      ],
      "metadata": {
        "id": "0-nH4o3YAA4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install vLLM from pip:\n",
        "!pip install vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xLQzt4NQAGAZ",
        "outputId": "1dbfdfa2-cb1f-4138-99de-7a69b39b85f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.7.2-cp38-abi3-manylinux1_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.48.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.48.3)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (4.25.6)\n",
            "Collecting fastapi!=0.113.*,!=0.114.0,>=0.107.0 (from vllm)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.12)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.61.1)\n",
            "Collecting uvicorn[standard] (from vllm)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.10.6)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.1.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.9 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.10-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar>=0.1.6 (from vllm)\n",
            "  Downloading xgrammar-0.1.13-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.17.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm) (24.0.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf==0.10.0 (from vllm)\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.6.1)\n",
            "Collecting mistral_common>=1.5.0 (from mistral_common[opencv]>=1.5.0->vllm)\n",
            "  Downloading mistral_common-1.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.9.1 (from vllm)\n",
            "  Downloading compressed_tensors-0.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Collecting ray>=2.9 (from ray[default]>=2.9->vllm)\n",
            "  Downloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting nvidia-ml-py>=12.560.30 (from vllm)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.20.1+cu124)\n",
            "Collecting xformers==0.0.28.post3 (from vllm)\n",
            "  Downloading xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from depyf==0.18.0->vllm)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.5)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20241001-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.11.0.86)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.5.0)\n",
            "Collecting aiohttp-cors (from ray[default]>=2.9->vllm)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default]>=2.9->vllm)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default]>=2.9->vllm)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (7.1.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default]>=2.9->vllm)\n",
            "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default]>=2.9->vllm)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (1.70.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.4.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.19.1->vllm) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.2->vllm) (0.5.2)\n",
            "Collecting pybind11 (from xgrammar>=0.1.6->vllm)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from xgrammar>=0.1.6->vllm) (8.3.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (14.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.22.3)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]>=2.9->vllm)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]>=2.9->vllm) (1.17.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]>=2.9->vllm) (2.19.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (1.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default]>=2.9->vllm) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.6.1)\n",
            "Downloading vllm-0.7.2-cp38-abi3-manylinux1_x86_64.whl (264.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.10-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.3-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl (67.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.13-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.4/402.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading airportsdata-20241001-py3-none-any.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py, distlib, colorful, blake3, virtualenv, uvloop, uvicorn, python-dotenv, pycountry, pybind11, partial-json-parser, msgspec, lark, interegular, httptools, gguf, diskcache, dill, astor, airportsdata, watchfiles, tiktoken, starlette, depyf, prometheus-fastapi-instrumentator, lm-format-enforcer, fastapi, aiohttp-cors, xformers, ray, outlines_core, opencensus, mistral_common, xgrammar, outlines, compressed-tensors, vllm\n",
            "Successfully installed aiohttp-cors-0.7.0 airportsdata-20241001 astor-0.8.1 blake3-1.0.4 colorful-0.5.6 compressed-tensors-0.9.1 depyf-0.18.0 dill-0.3.9 diskcache-5.6.3 distlib-0.3.9 fastapi-0.115.8 gguf-0.10.0 httptools-0.6.4 interegular-0.3.3 lark-1.2.2 lm-format-enforcer-0.10.10 mistral_common-1.5.3 msgspec-0.19.0 nvidia-ml-py-12.570.86 opencensus-0.11.4 opencensus-context-0.1.3 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.0.2 py-spy-0.4.0 pybind11-2.13.6 pycountry-24.6.1 python-dotenv-1.0.1 ray-2.42.1 starlette-0.45.3 tiktoken-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 virtualenv-20.29.2 vllm-0.7.2 watchfiles-1.0.4 xformers-0.0.28.post3 xgrammar-0.1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and run the model:\n",
        "!vllm serve \"google/paligemma-3b-pt-224\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dQ_u9IfyAINR",
        "outputId": "914072a3-1a83-45af-d32a-62b0fe0e0aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-17 08:26:07.187945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739780767.209283   42934 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739780767.215291   42934 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO 02-17 08:26:12 __init__.py:194] No platform detected, vLLM is running on UnspecifiedPlatform\n",
            "INFO 02-17 08:26:16 api_server.py:840] vLLM API server version 0.7.2\n",
            "INFO 02-17 08:26:16 api_server.py:841] args: Namespace(subparser='serve', model_tag='google/paligemma-3b-pt-224', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, enable_reasoning=False, reasoning_parser=None, tool_call_parser=None, tool_parser_plugin='', model='google/paligemma-3b-pt-224', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=None, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', generation_config=None, override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, dispatch_function=<function serve at 0x7f357855c040>)\n",
            "INFO 02-17 08:26:16 api_server.py:206] Started engine process with PID 43015\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/vllm\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/scripts.py\", line 204, in main\n",
            "    args.dispatch_function(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/scripts.py\", line 44, in serve\n",
            "    uvloop.run(run_server(args))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 105, in run\n",
            "    return runner.run(wrapper())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 61, in wrapper\n",
            "    return await main\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 875, in run_server\n",
            "    async with build_async_engine_client(args) as engine_client:\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 136, in build_async_engine_client\n",
            "    async with build_async_engine_client_from_engine_args(\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 217, in build_async_engine_client_from_engine_args\n",
            "    engine_config = engine_args.create_engine_config()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1074, in create_engine_config\n",
            "    device_config = DeviceConfig(device=self.device)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/config.py\", line 1626, in __init__\n",
            "    raise RuntimeError(\"Failed to infer device type\")\n",
            "RuntimeError: Failed to infer device type\n",
            "2025-02-17 08:26:24.784772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739780784.812466   43015 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739780784.820698   43015 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO 02-17 08:26:30 __init__.py:194] No platform detected, vLLM is running on UnspecifiedPlatform\n",
            "ERROR 02-17 08:26:32 engine.py:389] Failed to infer device type\n",
            "ERROR 02-17 08:26:32 engine.py:389] Traceback (most recent call last):\n",
            "ERROR 02-17 08:26:32 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 380, in run_mp_engine\n",
            "ERROR 02-17 08:26:32 engine.py:389]     engine = MQLLMEngine.from_engine_args(engine_args=engine_args,\n",
            "ERROR 02-17 08:26:32 engine.py:389]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 02-17 08:26:32 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 118, in from_engine_args\n",
            "ERROR 02-17 08:26:32 engine.py:389]     engine_config = engine_args.create_engine_config(usage_context)\n",
            "ERROR 02-17 08:26:32 engine.py:389]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 02-17 08:26:32 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1074, in create_engine_config\n",
            "ERROR 02-17 08:26:32 engine.py:389]     device_config = DeviceConfig(device=self.device)\n",
            "ERROR 02-17 08:26:32 engine.py:389]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 02-17 08:26:32 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/config.py\", line 1626, in __init__\n",
            "ERROR 02-17 08:26:32 engine.py:389]     raise RuntimeError(\"Failed to infer device type\")\n",
            "ERROR 02-17 08:26:32 engine.py:389] RuntimeError: Failed to infer device type\n",
            "Process SpawnProcess-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 391, in run_mp_engine\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 380, in run_mp_engine\n",
            "    engine = MQLLMEngine.from_engine_args(engine_args=engine_args,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 118, in from_engine_args\n",
            "    engine_config = engine_args.create_engine_config(usage_context)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1074, in create_engine_config\n",
            "    device_config = DeviceConfig(device=self.device)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/config.py\", line 1626, in __init__\n",
            "    raise RuntimeError(\"Failed to infer device type\")\n",
            "RuntimeError: Failed to infer device type\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "\n",
        "# Load the image-text-to-text model\n",
        "pipe = pipeline(\n",
        "    \"image-to-text\",\n",
        "    model=\"google/paligemma-3b-pt-224\",\n",
        "    model_kwargs={\"torch_dtype\": \"auto\"},\n",
        "    device=-1  # Use CPU\n",
        ")\n",
        "\n",
        "# Load an image correctly as a PIL image\n",
        "image_path = \"/content/sample_data/Screenshot 2025-02-14 115920.png\"  # Ensure this file exists\n",
        "image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB mode\n",
        "\n",
        "# Define a text prompt (optional)\n",
        "prompt = \"Describe this image in detail.\"\n",
        "\n",
        "# Pass the image and text correctly within a dictionary\n",
        "# The 'image' key should have the PIL image, and the 'text' key should have the prompt\n",
        "output = pipe({\"image\": image, \"text\": prompt}, max_new_tokens=100)\n",
        "\n",
        "# Print the result\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EtL9OXZAL_R",
        "outputId": "b8b7c3f8-7303-48da-8047-507250c61166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b373eb144fd468d99cd809866c1bed4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Incorrect format used for image. Should be an url linking to an image, a base64 string, a local path, or a PIL image.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-87ad6353dc38>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Pass the image and text correctly within a dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# The 'image' key should have the PIL image, and the 'text' key should have the prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Print the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/image_to_text.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call the image-to-text pipeline without an inputs argument!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/image_to_text.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, image, prompt, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(image, timeout)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0;34m\"Incorrect format used for image. Should be an url linking to an image, a base64 string, a local path, or a PIL image.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: Incorrect format used for image. Should be an url linking to an image, a base64 string, a local path, or a PIL image."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Groq Llama-3.2-11b-vision-preview"
      ],
      "metadata": {
        "id": "k3cLz0sYKU3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjRnL6OALlK7",
        "outputId": "36190fd6-e3cd-4e56-c77d-271e808fc258"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from groq import Groq\n",
        "# import base64\n",
        "# import requests\n",
        "# import os\n",
        "\n",
        "# # Set your Groq API key\n",
        "# os.environ[\"GROQ_API_KEY\"] = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# # Initialize the Groq client\n",
        "# client = Groq()\n",
        "\n",
        "# def analyze_image(image_path, text_prompt):\n",
        "#     # Read and encode the image in base64\n",
        "#     with open(image_path, \"rb\") as image_file:\n",
        "#         encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "#     # Define the payload\n",
        "#     messages = [\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": [\n",
        "#                 {\"type\": \"text\", \"text\": text_prompt},\n",
        "#                 {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}\n",
        "#             ]\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     # Call the Groq API\n",
        "#     completion = client.chat.completions.create(\n",
        "#         model=\"llama-3.2-11b-vision-preview\",\n",
        "#         messages=messages,\n",
        "#         temperature=1,\n",
        "#         max_completion_tokens=1024,\n",
        "#         top_p=1,\n",
        "#         stream=False,\n",
        "#         stop=None,\n",
        "#     )\n",
        "\n",
        "#     # Print the result\n",
        "#     return completion.choices[0].message.content\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     image_path = \"/content/sample_data/Screenshot 2025-02-17 192841.png\"  # Path to your image\n",
        "#     text_prompt = \"Analyze this image and provide insights.\"\n",
        "#     result = analyze_image(image_path, text_prompt)\n",
        "#     print(\"AI Analysis:\", result)\n",
        "\n",
        "\n",
        "from groq import Groq\n",
        "import base64\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Set your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Initialize the Groq client\n",
        "client = Groq()\n",
        "\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "    return text if text else \"No readable text found.\"\n",
        "\n",
        "def analyze_file(file_path, text_prompt):\n",
        "    if file_path.lower().endswith(\".pdf\"):\n",
        "        extracted_text = extract_text_from_pdf(file_path)\n",
        "        content = [{\"type\": \"text\", \"text\": f\"{text_prompt}\\nExtracted Text:\\n{extracted_text}\"}]\n",
        "    else:\n",
        "        encoded_image = encode_image(file_path)\n",
        "        content = [\n",
        "            {\"type\": \"text\", \"text\": text_prompt},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}\n",
        "        ]\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": content}]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.2-11b-vision-preview\",\n",
        "        messages=messages,\n",
        "        temperature=1,\n",
        "        max_completion_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=False,\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/sample_data/PS_2.1_011_1075_05_Relevante Eingangsgrößen für P3+ Anmeldepackage erzeugen.pdf\"  # Path to your file (image or PDF)\n",
        "    text_prompt = \"Analyze this file and provide insights.\"\n",
        "    result = analyze_file(file_path, text_prompt)\n",
        "    print(\"AI Analysis:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCAHzS7EKc0U",
        "outputId": "0c35e79c-8394-4a42-c902-c047a48cf69a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIStatusError",
          "evalue": "Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.2-11b-vision-preview` in organization `org_01jk7tcn4be9h8bya1x2691xaa` service tier `on_demand` on tokens per minute (TPM): Limit 7000, Requested 7652, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIStatusError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-923e03c74de3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/sample_data/PS_2.1_011_1075_05_Relevante Eingangsgrößen für P3+ Anmeldepackage erzeugen.pdf\"\u001b[0m  \u001b[0;31m# Path to your file (image or PDF)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mtext_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Analyze this file and provide insights.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AI Analysis:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-923e03c74de3>\u001b[0m in \u001b[0;36manalyze_file\u001b[0;34m(file_path, text_prompt)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"llama-3.2-11b-vision-preview\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    320\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         )\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    959\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mAPIStatusError\u001b[0m: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.2-11b-vision-preview` in organization `org_01jk7tcn4be9h8bya1x2691xaa` service tier `on_demand` on tokens per minute (TPM): Limit 7000, Requested 7652, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Split and Read Approach"
      ],
      "metadata": {
        "id": "FPjg4D5ERpfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX7yu59PPBJ",
        "outputId": "9dc63ae2-a024-4d40-8235-f0c4609ba1b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fitz in /usr/local/lib/python3.11/dist-packages (0.0.1.dev2)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.11/dist-packages (from fitz) (5.0.9)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.11/dist-packages (from fitz) (7.1.0)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.11/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from fitz) (5.3.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.11/dist-packages (from fitz) (1.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fitz) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fitz) (2.2.2)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.11/dist-packages (from fitz) (1.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fitz) (1.13.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2->fitz) (3.2.1)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (6.5.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (4.12.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (8.1.8)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.4.2)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (2.0.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.20.1)\n",
            "Requirement already satisfied: traits>=6.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (7.0.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.17.0)\n",
            "Requirement already satisfied: acres in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (0.2.0)\n",
            "Requirement already satisfied: etelemetry>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion!=1.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (1.28)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.1)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (5.3.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (2.32.3)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.11/dist-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (2025.1.31)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "\n",
        "def split_pdf(input_pdf, output_folder):\n",
        "    \"\"\"\n",
        "    Splits a PDF file into individual pages.\n",
        "\n",
        "    :param input_pdf: Path to the input PDF file.\n",
        "    :param output_folder: Folder where the split pages will be saved.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    doc = fitz.open(input_pdf)\n",
        "    num_pages = len(doc)  # Get the number of pages before closing the document\n",
        "    for page_num in range(num_pages):\n",
        "        output_pdf_path = os.path.join(output_folder, f\"page_{page_num + 1}.pdf\")\n",
        "        new_doc = fitz.open()\n",
        "        new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
        "        new_doc.save(output_pdf_path)\n",
        "        new_doc.close()\n",
        "\n",
        "    doc.close()\n",
        "    print(f\"PDF split into {num_pages} pages and saved in {output_folder}\")  # Use num_pages here\n",
        "\n",
        "def zoom_image_in_pdf(input_pdf, output_pdf, zoom_factor):\n",
        "    \"\"\"\n",
        "    Zooms images in a PDF file.\n",
        "\n",
        "    :param input_pdf: Path to the input PDF file.\n",
        "    :param output_pdf: Path to the output PDF file with zoomed images.\n",
        "    :param zoom_factor: Scaling factor for zooming.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(input_pdf)\n",
        "    mat = fitz.Matrix(zoom_factor, zoom_factor)\n",
        "\n",
        "    new_doc = fitz.open()\n",
        "\n",
        "    for page in doc:\n",
        "        pix = page.get_pixmap(matrix=mat)\n",
        "        img_page = new_doc.new_page(width=pix.width, height=pix.height)\n",
        "        img_page.insert_image(img_page.rect, pixmap=pix)\n",
        "\n",
        "    new_doc.save(output_pdf)\n",
        "    new_doc.close()\n",
        "    doc.close()\n",
        "    print(f\"Zoomed PDF saved as {output_pdf}\")\n",
        "\n",
        "# Example usage\n",
        "split_pdf(\"/content/zoomed_output.pdf\", \"split_pages\")\n",
        "# zoom_image_in_pdf(\"/content/sample_data/PS_2.1_011_1075_05_Relevante Eingangsgrößen für P3+ Anmeldepackage erzeugen.pdf\", \"zoomed_output.pdf\", 6.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6KiRBjaPALi",
        "outputId": "6ffbcb00-5faa-4a04-dc3c-59821fbd15e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF split into 11 pages and saved in split_pages\n"
          ]
        }
      ]
    }
  ]
}