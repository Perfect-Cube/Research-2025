![1752483607490](https://github.com/user-attachments/assets/4e5e222c-a8d9-4262-b21f-bbf8d025cbdc)

üîπ 1. Agentic Systems and RAG Pipelines

One of my primary focus areas was designing Agentic AI systems ‚Äî self-directed agents that can plan, collaborate, and solve tasks autonomously. I explored how multi-agent frameworks can be applied in enterprise and automotive contexts, particularly using:

    Langflow for building modular agentic workflows.

    AutoGen for dynamic planning, task delegation, and result synthesis.

    Langchain + Qwen2 + LLaMA + Gemma for building advanced RAG (Retrieval-Augmented Generation) pipelines.

Key Highlights:

    Built Agentic Onboarding Agents, Coding Agents, and Planning Agents capable of reasoning through tasks like generating blog posts, onboarding documents, stock reports, and software snippets.

    Created Graph Visualizations of Agent Collaboration, showing how agents interact, delegate tasks, and handle dependencies using GPT-based planners.

    Developed parallel execution systems where agents run asynchronously, improving system efficiency.

üîπ 2. Immersive Metaverse Development (AR/VR/XR)

I worked on designing metaverse-ready 3D environments and experiences that showcase the future of immersive user interaction in the automotive industry.

    Apple Vision Pro-ready 3D Scenes: Created interactive environments using GLB/FBX models of Audi and Volkswagen cars, production lines, robot arms, and showrooms.

    Built Metaverse Factories and Digital Twins with detailed simulations of industrial robots, assembly lines, and spatial walkthroughs.

    Developed experiences for The Metaverse Oculus and Quantum Worlds, combining VR environments with real-world car models and brand narratives.

    Created scenes using real car assets like Audi R8, RS6 Avant, Skoda Citigo, Volkswagen Beetle, Porsche 911, and electric ID.Buzz.

Tools Used: Blender, Unreal Engine, Unity (interoperability), custom 3D scripting (OpenGL/GLTF), RealityKit (for Apple Vision Pro), .fbx/.glb scene conversion tools.
üîπ 3. Digital Avatars & Real-Time 3D Interaction

I developed an intelligent digital avatar named ‚ÄúNikhil‚Äù, capable of interpreting voice and facial gestures for dynamic human-AI interaction.

    Integrated Intel RealSense D435i RGB-D Camera for depth + video input.

    Built facial expression pipelines and audio-triggered animations.

    Developed scripts for avatars that listen, respond, and emote ‚Äî combining Python, GLB avatars, and Metahuman character rigging.

Also built pipeline utilities to:

    Convert real-world objects (captured via point cloud) into usable GLB avatars.

    Generate audio-to-face triggers (like waving gestures + speaking in sync).

üîπ 4. ML-based Inventory Forecasting System

To optimize the automotive supply chain, I designed and tested a Machine Learning-based Inventory Management System for proactive decision-making.

    Simulated warehouse‚Äìassembly‚Äìshowroom systems.

    Built XGBoost-based predictors to forecast part consumption and reordering needs.

    Generated synthetic data for warehouses, stations, and suppliers to model real-world scenarios.

    Tracked agent decisions, order history, and dynamic inventory flow.

UI and agent logic were built in Python, with dashboards showcasing predicted shortages and suggested orders.
üîπ 5. Quantum AI Projects

I also explored Quantum-Inspired Algorithms and Optimization for computer vision and simulation tasks:

    Developed Quantum Non-Local Means (NLM) models to denoise and upscale blurry images.

    Worked on Quantum Metallurgy Optimization using simulation techniques for material sciences.

    Researched Quantum Reaction Simulations for Fuel Cell Catalysis, relevant to electric vehicle (EV) energy systems.

These projects combined quantum research papers, Python-based simulators, and SciPy/QML frameworks for experimentation.
üîπ 6. Computer Vision + AI Agents

I built a number of Image + Text agents using:

    BLIP (Bootstrapping Language-Image Pretraining)

    SmolVLM, Salesforce models, and custom image captioning models

These agents were able to:

    Classify, caption, and search for similar images

    Power multimodal RAG pipelines for document + image inputs

    Moderate unsafe or irrelevant content via AI-based filtering

üîπ 7. Backtrack.AI ‚Äì Safe Content Moderation System

Created a safe AI moderation pipeline for social media/video content platforms:

    Prefiltered unsafe inputs using LLM + CV agent reasoning

    Implemented post-filtering for edge-case handling and adversarial examples

    Designed evaluation pipelines and ZIP-packaged final software as SafeTrackAI

üîπ 8. Point Cloud Reconstruction

Used Intel RealSense and Open3D to:

    Capture and process point clouds from real environments

    Filter and optimize 3D scenes

    Export them to .ply/.glb formats for metaverse or AR integrations

Also integrated these assets with avatar generation and spatial interaction logic.
üîπ 9. Agentic Drone Simulation

Designed drone behavior simulation agents that:

    Take mission inputs and adapt actions in real time

    Switch between trivial/non-trivial goals

    Use async and multi-agent planning via AutoGen pipelines

This simulated how autonomous drones could operate in volatile or uncertain environments ‚Äî applicable to warehouse delivery or remote maintenance bots.
üîπ 10. Chatbot UI with Next.js

Built a production-ready chatbot interface using:

    Next.js + React

    Integrated with various LLM APIs (OpenAI, Groq, Gemini)

    Support for fullscreen modes, user logging, and multi-modal inputs

üéØ Technologies & Tools Used

    Languages: Python, JavaScript (Next.js), TypeScript, Bash

    Frameworks: AutoGen, LangFlow, Langchain, Streamlit, Gradio

    Libraries: OpenCV, Scikit-learn, XGBoost, HuggingFace, Open3D

    3D & XR: Unreal Engine, Blender, GLTF, RealityKit, Intel RealSense SDK

    Quantum: SciPy, Custom QML Simulators, Research papers

    Cloud & Infra: AWS (for testing), GitHub Actions

    Others: NVIDIA CUDA (certified), FBX/GLB asset pipelines, Kaggle notebooks

üìä Impact & Outcomes

    Developed over 20 modular R&D pipelines across AI, XR, Quantum, and ML domains.

    Helped bridge the gap between digital and physical ‚Äì through avatars, simulations, and immersive scenes.

    Prototyped intelligent systems that think, talk, act, and learn ‚Äì powered by LLMs, real-world inputs, and agentic frameworks.

    Enabled a vision of autonomous systems that could someday operate factories, assist users, and optimize logistics with minimal human supervision.

1. https://www.mdpi.com/1996-1073/16/1/442
2.  https://spectrum.ieee.org/lithium-air-battery-quantum-computing
3. https://arxiv.org/pdf/2408.06160
4. https://thequantuminsider.com/2022/04/13/psiquantum-mercedes-benz-study-how-quantum-computers-can-accelerate-ev-battery-design/
5. http://arxiv.org/pdf/2006.04594
6. https://www.honeywell.com/us/en/news/2021/01/exploring-supply-chain-solutions-with-quantum-computing

50 use case production, manufacture,assembly line
Structure analysis 
Faster convergence  ML Models
Hybrid systems 
Fast image analysis 
More latency issue, bandwidth more req


![1738831511017](https://github.com/user-attachments/assets/47e3ff95-4dd4-4b9e-a987-ee9feb6433ac)


![image](https://github.com/user-attachments/assets/107e916b-b70f-4e49-9d0f-29323517ff9d)


![image](https://github.com/user-attachments/assets/ddbad4ed-bb6d-484f-854f-87330bc4925b)
